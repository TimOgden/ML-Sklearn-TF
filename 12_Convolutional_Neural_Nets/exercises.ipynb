{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What are the advantages of a CNN over a fully connected DNN for image classification?**\n",
    "\n",
    "Convolutional layers have *partially connected* neurons, so in large images, the number of parameters is much more manageable. Also, in each feature map in a conv layer, all the neurons share the same weights and bias terms, meaning that a) there is way fewer parameters and b) if the network learns how to detect a certain feature, it will be able to detect that feature over the whole image, unlike a DNN where it has to learn to detect that same feature multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Consider a CNN composed of three convolutional layers, each with 3x3 kernels, a stride of 2, and SAME padding. The lowest layer outputs 100 feature maps, the middle one outputs 200, and the top one outputs 400. The input images are RGB images of 200x300 pixels. What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much RAM will this network require when making a prediction for a single instance? What about when training on a mini-batch of 50 images?**\n",
    "\n",
    "The total number of parameters per layer would be (kernel_area x num_channels + 1 (for bias)) x num_filters. Thus, we have\n",
    "\n",
    "( (3x3x3+1)  x 100 ) + ( (3x3x3+1) x 200 ) + ( (3x3x3+1) x 400 ) = 2800 + 5600 + 11200 = 19,600 total parameters.\n",
    "\n",
    "If we are inferencing on a single instance, we only need at maximum, enough RAM to hold the largest two consecutive layers in memory. Since we have strides of 2 in all our layers, that means that the first conv has (100x150x100)=1,500,000 neurons, then the second would has (50x75x200)=3,000,000 neurons, then the last has (25x38x400)=6,000,000 neurons, and each neuron has 3^3=27 inputs, so when training on a mini-batch of 50 images, you would need 27x(1,500,000+3,000,000+6,000,000)x32x50 bits = 56,700 Mb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. If your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?**\n",
    "\n",
    "- Decrease the batch size\n",
    "\n",
    "- Use a stride to decrease dimensionality.\n",
    "\n",
    "- Use less layers.\n",
    "\n",
    "- Use a pooling layer.\n",
    "\n",
    "- Use 16-bit floats rather than 32-bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While convolutional layers with a stride > 1 will be able to output smaller images than their inputs, they still add a lot of complexity. There are parameters based on the kernel size, the number of channels, and the number of feature maps. A pooling layer will shrink the image the same way, but it doesn't have any weight values and thus is not trainable. Pooling layers are very useful for removing complexity from the network, and thus reducing the possibility of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. When would you want to add a local response normalization layer?**\n",
    "\n",
    "If you want to increase the generalizability of your network, adding local response normalization is a good idea because it will encourage each layer to find a range of feature maps that are very different from one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Can you name the main innovations in AlexNet compared to LeNet-5? What about the main innovations in GoogLeNet and ResNet?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main innovation of AlexNet compared to LeNet-5 was the fact that it was much deeper than LeNet. It also stacked multiple Conv layers in succession, and AlexNet used local response normalization.\n",
    "\n",
    "The main innovation of ResNet over GoogLeNet was the introduction of skip connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Build your own CNN and try to achieve the highest possible accuracy on MNIST.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What I want to implement in this CNN\n",
    "# 1. Data augmentation\n",
    "# 2. Not too large, about the size of AlexNet\n",
    "# 3. Some regularization techniques\n",
    "# 4. *Maybe* implementing local response regularization\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = tf.keras.layers.Input((28,28,1))\n",
    "conv1 = tf.keras.layers.Conv2D(5, 3, strides=2, padding='SAME', \n",
    "                               activation=tf.keras.activations.elu,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l=0.02))(img_input)\n",
    "batch_norm_a = tf.keras.layers.BatchNormalization()(conv1)\n",
    "pool2 = tf.keras.layers.MaxPool2D(2)(batch_norm_a)\n",
    "conv3 = tf.keras.layers.Conv2D(10, 3, strides=2, padding='SAME',\n",
    "                               activation=tf.keras.activations.elu,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l=0.02))(pool2)\n",
    "batch_norm_b = tf.keras.layers.BatchNormalization()(conv3)\n",
    "flatten4 = tf.keras.layers.Flatten()(batch_norm_b)\n",
    "dense5 = tf.keras.layers.Dense(50, activation=tf.keras.activations.elu)(flatten4)\n",
    "dropout6 = tf.keras.layers.Dropout(.5)(dense5)\n",
    "dense7 = tf.keras.layers.Dense(10, activation='softmax')(dropout6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Model(inputs=[img_input], outputs=[dense7])\n",
    "cnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 5)         50        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 5)         20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 10)          460       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 10)          40        \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                8050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 9,130\n",
      "Trainable params: 9,100\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((-1,28,28,1))\n",
    "x_test = x_test.reshape((-1,28,28,1));\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_std_normalization=True, featurewise_center=True,\n",
    "    rotation_range=20, shear_range=3,\n",
    "    rescale=1/255.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=2,restore_best_weights=True)\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "   2/1875 [..............................] - ETA: 13:08 - loss: 0.5963 - accuracy: 0.7812WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.429220). Check your callbacks.\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4814 - accuracy: 0.8656 - val_loss: 1.0729 - val_accuracy: 0.6326\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3933 - accuracy: 0.8922 - val_loss: 0.9133 - val_accuracy: 0.6911\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.3641 - accuracy: 0.9007 - val_loss: 1.0287 - val_accuracy: 0.6605\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3449 - accuracy: 0.9071 - val_loss: 0.8419 - val_accuracy: 0.7339\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.3300 - accuracy: 0.9104 - val_loss: 0.6152 - val_accuracy: 0.8476\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.3252 - accuracy: 0.9121 - val_loss: 0.8907 - val_accuracy: 0.6910\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3155 - accuracy: 0.9160 - val_loss: 0.9463 - val_accuracy: 0.6728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1792e5aaa60>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(datagen.flow(x_train, y_train, batch_size=32), validation_data=(x_test, y_test), \n",
    "        callbacks=[early_stop, tensorboard], epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Transfer learning for large image classification.**\n",
    "\n",
    "*a. Load in the flowers dataset.*\n",
    "\n",
    "*b. Resize and crop the images to 299x299 pixels with some randomness for data augmentation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, shear_range=0.2, zoom_range=0.2,horizontal_flip=True , validation_split=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*c. Use a pretrained Inception v3 model, freeze all layers up to the bottleneck layer... and replace the output layer with the appropriate number of outputs for your new classification task*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3 = tf.keras.applications.InceptionV3(include_top=False)\n",
    "x = inceptionv3.output\n",
    "for layer in inceptionv3.layers:\n",
    "    layer.trainable = False\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(.4)(x)\n",
    "output = tf.keras.layers.Dense(5, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 3 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 3 96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 3 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, None, None, 3 9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, None, 3 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 3 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, None, None, 6 18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, None, 6 192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 6 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 6 0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, None, None, 8 5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, None, 8 240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 8 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, None, None, 1 138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, None, 1 576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, None, 1 0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 1 0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, None, None, 6 192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, None, 6 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, None, None, 9 55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, None, None, 4 144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, None, None, 9 288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, None, 4 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, None, 9 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 1 0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, None, None, 6 12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, None, None, 6 76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, None, None, 9 82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, None, 6 192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, None, None, 6 192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, None, None, 9 288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, None, None, 3 96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, None, 6 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, None, 6 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, None, 9 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, None, 3 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, None, None, 6 192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, None, 6 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, None, None, 9 55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, None, None, 4 144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, None, None, 9 288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, None, 4 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, None, 9 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, None, None, 6 76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, None, None, 9 82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, None, None, 6 192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, None, None, 6 192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, None, None, 9 288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, None, None, 6 192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, None, 6 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, None, 6 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, None, 9 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, None, 6 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, None, None, 6 192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, None, 6 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, None, None, 9 55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, None, None, 4 144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, None, None, 9 288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, None, 4 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, None, 9 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, None, None, 6 76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, None, None, 9 82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, None, None, 6 192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, None, None, 6 192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, None, None, 9 288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, None, None, 6 192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, None, 6 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, None, 6 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, None, 9 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, None, 6 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, None, None, 6 192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, None, 6 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, None, None, 9 55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, None, None, 9 288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, None, 9 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, None, None, 9 82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, None, None, 3 1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, None, None, 9 288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, None, 3 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, None, 9 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, None, None, 1 384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, None, 1 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, None, None, 1 114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, None, None, 1 384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, None, 1 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, None, None, 1 114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, None, None, 1 384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, None, None, 1 384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, None, 1 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, None, 1 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, None, None, 1 114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, None, None, 1 114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, None, None, 1 384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, None, None, 1 384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, None, 1 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, None, 1 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, None, None, 1 172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, None, None, 1 172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, None, None, 1 576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, None, None, 1 576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, None, None, 1 576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, None, None, 1 576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, None, None, 1 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, None, 1 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, None, 1 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, None, 1 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, None, None, 1 480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, None, 1 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, None, None, 1 179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, None, None, 1 480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, None, 1 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, None, None, 1 179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, None, None, 1 480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, None, None, 1 480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, None, 1 0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, None, None, 1 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, None, None, 1 179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, None, None, 1 179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, None, None, 1 480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, None, None, 1 480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, None, 1 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, None, None, 1 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, None, None, 1 215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, None, None, 1 215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, None, None, 1 576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, None, None, 1 576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, None, None, 1 576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, None, None, 1 576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, None, 1 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, None, 1 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, None, None, 1 0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, None, None, 1 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, None, None, 1 480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, None, None, 1 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, None, None, 1 179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, None, None, 1 480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, None, None, 1 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, None, None, 1 179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, None, None, 1 480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, None, None, 1 480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, None, None, 1 0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, None, None, 1 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, None, None, 1 179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, None, None, 1 179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, None, None, 1 480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, None, None, 1 480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, None, None, 1 0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, None, None, 1 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, None, None, 1 215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, None, None, 1 215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, None, None, 1 576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, None, None, 1 576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, None, None, 1 576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, None, None, 1 576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, None, None, 1 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, None, None, 1 0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, None, None, 1 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, None, None, 1 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, None, None, 1 576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, None, None, 1 0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, None, None, 1 258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, None, None, 1 576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, None, None, 1 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, None, None, 1 258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, None, None, 1 576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, None, None, 1 576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, None, None, 1 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, None, None, 1 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, None, None, 1 258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, None, None, 1 258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, None, None, 1 576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, None, None, 1 576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, None, None, 1 0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, None, None, 1 0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, None, None, 1 258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, None, None, 1 258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, None, None, 1 576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, None, None, 1 576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, None, None, 1 576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, None, None, 1 576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, None, None, 1 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, None, None, 1 0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, None, None, 1 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, None, None, 1 0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, None, None, 1 576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, None, None, 1 0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, None, None, 1 258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, None, None, 1 576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, None, None, 1 0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, None, None, 1 258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, None, None, 1 576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, None, None, 1 576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, None, None, 1 0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, None, None, 1 0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, None, None, 3 552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, None, None, 1 331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, None, None, 3 960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, None, None, 1 576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, None, None, 3 0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, None, None, 1 0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, None, None, 4 1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, None, None, 4 0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, None, None, 3 1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, None, None, 3 1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, None, None, 3 1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, None, None, 3 0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, None, None, 3 0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, None, None, 3 442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, None, None, 3 442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, None, None, 3 442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, None, None, 3 442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, None, None, 3 1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, None, None, 3 1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, None, None, 3 1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, None, None, 3 1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, None, None, 3 960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, None, None, 3 0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, None, None, 3 0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, None, None, 3 0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, None, None, 3 0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, None, None, 1 576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, None, None, 3 0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, None, None, 1 0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, None, None, 4 1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, None, None, 4 0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, None, None, 3 1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, None, None, 3 1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, None, None, 3 1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, None, None, 3 0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, None, None, 3 0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, None, None, 3 442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, None, None, 3 442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, None, None, 3 442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, None, None, 3 442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, None, None, 3 1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, None, None, 3 1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, None, None, 3 1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, None, None, 3 1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, None, None, 3 960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, None, None, 3 0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, None, None, 3 0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, None, None, 3 0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, None, None, 3 0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, None, None, 1 576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, None, None, 3 0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 7 0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, None, None, 1 0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            10245       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,813,029\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_inception = tf.keras.models.Model(inputs=[inceptionv3.input], outputs=[output])\n",
    "my_inception.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "my_inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, True, True, True]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[layer.trainable for layer in my_inception.layers[-5:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*d. Split your dataset into a training set and a test set. Train the model on the training set and evaluate it on the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/FlowersDataset/flower_photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 5]), TensorShape([None, 2048]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(my_inception.layers[-1].output.shape, my_inception.layers[-2].output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2939 images belonging to 5 classes.\n",
      "Found 731 images belonging to 5 classes.\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 472s 5s/step - loss: 0.8548 - accuracy: 0.6778 - val_loss: 0.5422 - val_accuracy: 0.7989\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 458s 5s/step - loss: 0.4865 - accuracy: 0.8295 - val_loss: 0.4497 - val_accuracy: 0.8536\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 734s 8s/step - loss: 0.4250 - accuracy: 0.8438 - val_loss: 0.4353 - val_accuracy: 0.8427\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 772s 8s/step - loss: 0.3749 - accuracy: 0.8646 - val_loss: 0.4103 - val_accuracy: 0.8605\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3828f34c63d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m my_inception.fit(datagen.flow_from_directory(folder, target_size=(299,299),subset='training'),\n\u001b[0m\u001b[0;32m      2\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 epochs=20)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_inception.fit(datagen.flow_from_directory(folder, target_size=(299,299),subset='training'),\n",
    "                validation_data=datagen.flow_from_directory(folder, target_size=(299,299), subset='validation'),\n",
    "                epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 256, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen.flow_from_directory(folder).__next__()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Go through TensorFlow's DeepDream tutorial.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024C81F61C10>) with an unsupported type (<class 'tensorflow.python.keras.layers.convolutional.Conv2D'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mlrn\u001b[1;34m(input, depth_radius, bias, alpha, beta, name)\u001b[0m\n\u001b[0;32m   4806\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4807\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   4808\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"LRN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-de68d1e053c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlocal_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_response_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mlrn\u001b[1;34m(input, depth_radius, bias, alpha, beta, name)\u001b[0m\n\u001b[0;32m   4812\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4813\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4814\u001b[1;33m         return lrn_eager_fallback(\n\u001b[0m\u001b[0;32m   4815\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_radius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepth_radius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4816\u001b[0m             beta=beta, name=name, ctx=_ctx)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mlrn_eager_fallback\u001b[1;34m(input, depth_radius, bias, alpha, beta, name, ctx)\u001b[0m\n\u001b[0;32m   4877\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4878\u001b[0m   \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"beta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4879\u001b[1;33m   \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4880\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4881\u001b[0m   _attrs = (\"depth_radius\", depth_radius, \"bias\", bias, \"alpha\", alpha,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[1;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m       ret.append(\n\u001b[1;32m--> 262\u001b[1;33m           ops.convert_to_tensor(\n\u001b[0m\u001b[0;32m    263\u001b[0m               t, dtype, preferred_dtype=default_dtype, ctx=ctx))\n\u001b[0;32m    264\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    319\u001b[0m                                          as_ref=False):\n\u001b[0;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m--> 261\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    262\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024C81F61C10>) with an unsupported type (<class 'tensorflow.python.keras.layers.convolutional.Conv2D'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "conv1 = tf.keras.layers.Conv2D(100, 3, input_shape=(None,None,3))\n",
    "local_response = tf.nn.local_response_normalization(conv1)\n",
    "dense = tf.keras.layers.Dense(10, activation='softmax')(local_response)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[conv1], outputs=[dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
