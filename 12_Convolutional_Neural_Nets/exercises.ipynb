{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What are the advantages of a CNN over a fully connected DNN for image classification?**\n",
    "\n",
    "Convolutional layers have *partially connected* neurons, so in large images, the number of parameters is much more manageable. Also, in each feature map in a conv layer, all the neurons share the same weights and bias terms, meaning that a) there is way fewer parameters and b) if the network learns how to detect a certain feature, it will be able to detect that feature over the whole image, unlike a DNN where it has to learn to detect that same feature multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Consider a CNN composed of three convolutional layers, each with 3x3 kernels, a stride of 2, and SAME padding. The lowest layer outputs 100 feature maps, the middle one outputs 200, and the top one outputs 400. The input images are RGB images of 200x300 pixels. What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much RAM will this network require when making a prediction for a single instance? What about when training on a mini-batch of 50 images?**\n",
    "\n",
    "The total number of parameters per layer would be (kernel_area x num_channels + 1 (for bias)) x num_filters. Thus, we have\n",
    "\n",
    "( (3x3x3+1)  x 100 ) + ( (3x3x3+1) x 200 ) + ( (3x3x3+1) x 400 ) = 2800 + 5600 + 11200 = 19,600 total parameters.\n",
    "\n",
    "If we are inferencing on a single instance, we only need at maximum, enough RAM to hold the largest two consecutive layers in memory. Since we have strides of 2 in all our layers, that means that the first conv has (100x150x100)=1,500,000 neurons, then the second would has (50x75x200)=3,000,000 neurons, then the last has (25x38x400)=6,000,000 neurons, and each neuron has 3^3=27 inputs, so when training on a mini-batch of 50 images, you would need 27x(1,500,000+3,000,000+6,000,000)x32x50 bits = 56,700 Mb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. If your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?**\n",
    "\n",
    "- Decrease the batch size\n",
    "\n",
    "- Use a stride to decrease dimensionality.\n",
    "\n",
    "- Use less layers.\n",
    "\n",
    "- Use a pooling layer.\n",
    "\n",
    "- Use 16-bit floats rather than 32-bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While convolutional layers with a stride > 1 will be able to output smaller images than their inputs, they still add a lot of complexity. There are parameters based on the kernel size, the number of channels, and the number of feature maps. A pooling layer will shrink the image the same way, but it doesn't have any weight values and thus is not trainable. Pooling layers are very useful for removing complexity from the network, and thus reducing the possibility of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. When would you want to add a local response normalization layer?**\n",
    "\n",
    "If you want to increase the generalizability of your network, adding local response normalization is a good idea because it will encourage each layer to find a range of feature maps that are very different from one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Can you name the main innovations in AlexNet compared to LeNet-5? What about the main innovations in GoogLeNet and ResNet?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main innovation of AlexNet compared to LeNet-5 was the fact that it was much deeper than LeNet. It also stacked multiple Conv layers in succession, and AlexNet used local response normalization.\n",
    "\n",
    "The main innovation of ResNet over GoogLeNet was the introduction of skip connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Build your own CNN and try to achieve the highest possible accuracy on MNIST.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What I want to implement in this CNN\n",
    "# 1. Data augmentation\n",
    "# 2. Not too large, about the size of AlexNet\n",
    "# 3. Some regularization techniques\n",
    "# 4. *Maybe* implementing local response regularization\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = tf.keras.layers.Input((28,28,1))\n",
    "conv1 = tf.keras.layers.Conv2D(5, 3, strides=2, padding='SAME', \n",
    "                               activation=tf.keras.activations.elu,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l=0.02))(img_input)\n",
    "batch_norm_a = tf.keras.layers.BatchNormalization()(conv1)\n",
    "pool2 = tf.keras.layers.MaxPool2D(2)(batch_norm_a)\n",
    "conv3 = tf.keras.layers.Conv2D(10, 3, strides=2, padding='SAME',\n",
    "                               activation=tf.keras.activations.elu,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l=0.02))(pool2)\n",
    "batch_norm_b = tf.keras.layers.BatchNormalization()(conv3)\n",
    "flatten4 = tf.keras.layers.Flatten()(batch_norm_b)\n",
    "dense5 = tf.keras.layers.Dense(50, activation=tf.keras.activations.elu)(flatten4)\n",
    "dropout6 = tf.keras.layers.Dropout(.5)(dense5)\n",
    "dense7 = tf.keras.layers.Dense(10, activation='softmax')(dropout6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Model(inputs=[img_input], outputs=[dense7])\n",
    "cnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 5)         50        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 5)         20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 10)          460       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 10)          40        \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                8050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 9,130\n",
      "Trainable params: 9,100\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((-1,28,28,1))\n",
    "x_test = x_test.reshape((-1,28,28,1));\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_std_normalization=True, featurewise_center=True,\n",
    "    rotation_range=20, shear_range=3,\n",
    "    rescale=1/255.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=2,restore_best_weights=True)\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "   2/1875 [..............................] - ETA: 13:08 - loss: 0.5963 - accuracy: 0.7812WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.429220). Check your callbacks.\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4814 - accuracy: 0.8656 - val_loss: 1.0729 - val_accuracy: 0.6326\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3933 - accuracy: 0.8922 - val_loss: 0.9133 - val_accuracy: 0.6911\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.3641 - accuracy: 0.9007 - val_loss: 1.0287 - val_accuracy: 0.6605\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3449 - accuracy: 0.9071 - val_loss: 0.8419 - val_accuracy: 0.7339\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.3300 - accuracy: 0.9104 - val_loss: 0.6152 - val_accuracy: 0.8476\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.3252 - accuracy: 0.9121 - val_loss: 0.8907 - val_accuracy: 0.6910\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3155 - accuracy: 0.9160 - val_loss: 0.9463 - val_accuracy: 0.6728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1792e5aaa60>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(datagen.flow(x_train, y_train, batch_size=32), validation_data=(x_test, y_test), \n",
    "        callbacks=[early_stop, tensorboard], epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Transfer learning for large image classification.**\n",
    "\n",
    "*a. Load in the flowers dataset.*\n",
    "\n",
    "*b. Resize and crop the images to 299x299 pixels with some randomness for data augmentation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, shear_range=0.2, zoom_range=0.2,horizontal_flip=True , validation_split=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*c. Use a pretrained Inception v3 model, freeze all layers up to the bottleneck layer... and replace the output layer with the appropriate number of outputs for your new classification task*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3 = tf.keras.applications.InceptionV3(include_top=False)\n",
    "x = inceptionv3.output\n",
    "for layer in inceptionv3.layers:\n",
    "    layer.trainable = False\n",
    "output = tf.keras.layers.Dense(5, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, None, None, 3 864         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, None, None, 3 96          conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, None, None, 3 0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, None, None, 3 9216        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, None, None, 3 96          conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, None, None, 3 0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, None, None, 6 18432       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, None, None, 6 192         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, None, None, 6 0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, None, None, 6 0           activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, None, None, 8 5120        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, None, None, 8 240         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, None, None, 8 0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, None, None, 1 138240      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, None, None, 1 576         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, None, None, 1 0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, None, None, 1 0           activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, None, None, 6 192         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, None, None, 6 0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, None, None, 9 55296       activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, None, None, 4 144         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, None, None, 9 288         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, None, None, 4 0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, None, None, 9 0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, None, None, 1 0           max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, None, None, 6 76800       activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, None, None, 9 82944       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, None, None, 6 192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, None, None, 6 192         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, None, None, 9 288         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, None, None, 3 96          conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, None, None, 6 0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, None, None, 6 0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, None, None, 9 0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, None, None, 3 0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_287[0][0]             \n",
      "                                                                 activation_289[0][0]             \n",
      "                                                                 activation_292[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, None, None, 6 192         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, None, None, 6 0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, None, None, 9 55296       activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, None, None, 4 144         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, None, None, 9 288         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, None, None, 4 0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, None, None, 9 0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, None, None, 6 76800       activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, None, None, 9 82944       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, None, None, 6 192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, None, None, 6 192         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, None, None, 9 288         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, None, None, 6 192         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, None, None, 6 0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, None, None, 6 0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, None, None, 9 0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, None, None, 6 0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_294[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "                                                                 activation_299[0][0]             \n",
      "                                                                 activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, None, None, 6 192         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, None, None, 6 0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, None, None, 9 55296       activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, None, None, 4 144         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, None, None, 9 288         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, None, None, 4 0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, None, None, 9 0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, None, None, 6 76800       activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, None, None, 9 82944       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, None, None, 6 192         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, None, None, 6 192         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, None, None, 9 288         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, None, None, 6 192         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, None, None, 6 0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, None, None, 6 0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, None, None, 9 0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, None, None, 6 0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_301[0][0]             \n",
      "                                                                 activation_303[0][0]             \n",
      "                                                                 activation_306[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, None, None, 6 192         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, None, None, 6 0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, None, None, 9 55296       activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, None, None, 9 288         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, None, None, 9 0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, None, None, 9 82944       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, None, None, 3 1152        conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, None, None, 9 288         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, None, None, 3 0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, None, None, 9 0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_308[0][0]             \n",
      "                                                                 activation_311[0][0]             \n",
      "                                                                 max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, None, None, 1 384         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, None, None, 1 0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, None, None, 1 114688      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, None, None, 1 384         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, None, None, 1 0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, None, None, 1 114688      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, None, None, 1 384         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, None, None, 1 384         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, None, None, 1 0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, None, None, 1 0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, None, None, 1 114688      activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, None, None, 1 114688      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, None, None, 1 384         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, None, None, 1 384         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, None, None, 1 0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, None, None, 1 0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, None, None, 1 172032      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, None, None, 1 172032      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, None, None, 1 576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, None, None, 1 576         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, None, None, 1 576         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, None, None, 1 576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, None, None, 1 0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, None, None, 1 0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, None, None, 1 0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, None, None, 1 0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_312[0][0]             \n",
      "                                                                 activation_315[0][0]             \n",
      "                                                                 activation_320[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, None, None, 1 480         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, None, None, 1 0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, None, None, 1 179200      activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, None, None, 1 480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, None, None, 1 0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, None, None, 1 179200      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, None, None, 1 480         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, None, None, 1 480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, None, None, 1 0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, None, None, 1 0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, None, None, 1 179200      activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, None, None, 1 179200      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, None, None, 1 480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, None, None, 1 480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, None, None, 1 0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, None, None, 1 0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, None, None, 1 215040      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, None, None, 1 215040      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, None, None, 1 576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, None, None, 1 576         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, None, None, 1 576         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, None, None, 1 576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, None, None, 1 0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, None, None, 1 0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, None, None, 1 0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, None, None, 1 0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_322[0][0]             \n",
      "                                                                 activation_325[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, None, None, 1 480         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, None, None, 1 0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, None, None, 1 179200      activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, None, None, 1 480         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, None, None, 1 0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, None, None, 1 179200      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, None, None, 1 480         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, None, None, 1 480         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, None, None, 1 0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, None, None, 1 0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, None, None, 1 179200      activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, None, None, 1 179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, None, None, 1 480         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, None, None, 1 480         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, None, None, 1 0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, None, None, 1 0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, None, None, 1 215040      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, None, None, 1 215040      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, None, None, 1 576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, None, None, 1 576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, None, None, 1 576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, None, None, 1 576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, None, None, 1 0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, None, None, 1 0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, None, None, 1 0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, None, None, 1 0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_332[0][0]             \n",
      "                                                                 activation_335[0][0]             \n",
      "                                                                 activation_340[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, None, None, 1 576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, None, None, 1 0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, None, None, 1 258048      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, None, None, 1 576         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, None, None, 1 0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, None, None, 1 258048      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, None, None, 1 576         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, None, None, 1 576         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, None, None, 1 0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, None, None, 1 0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, None, None, 1 258048      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, None, None, 1 258048      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, None, None, 1 576         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, None, None, 1 576         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, None, None, 1 0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, None, None, 1 0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, None, None, 1 258048      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, None, None, 1 258048      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, None, None, 1 576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, None, None, 1 576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, None, None, 1 576         conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, None, None, 1 576         conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, None, None, 1 0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, None, None, 1 0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, None, None, 1 0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, None, None, 1 0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_342[0][0]             \n",
      "                                                                 activation_345[0][0]             \n",
      "                                                                 activation_350[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, None, None, 1 576         conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, None, None, 1 0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, None, None, 1 258048      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, None, None, 1 576         conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, None, None, 1 0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, None, None, 1 258048      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, None, None, 1 576         conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, None, None, 1 576         conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, None, None, 1 0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, None, None, 1 0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, None, None, 3 552960      activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, None, None, 1 331776      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, None, None, 3 960         conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, None, None, 1 576         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, None, None, 3 0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, None, None, 1 0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_353[0][0]             \n",
      "                                                                 activation_357[0][0]             \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, None, None, 4 1344        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, None, None, 4 0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, None, None, 3 1548288     activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, None, None, 3 1152        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, None, None, 3 1152        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, None, None, 3 0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, None, None, 3 0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, None, None, 3 442368      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, None, None, 3 442368      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, None, None, 3 442368      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, None, None, 3 442368      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, None, None, 3 1152        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, None, None, 3 1152        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, None, None, 3 1152        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, None, None, 3 1152        conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, None, None, 3 960         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, None, None, 3 0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, None, None, 3 0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, None, None, 3 0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, None, None, 3 0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, None, None, 1 576         conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, None, None, 3 0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_360[0][0]             \n",
      "                                                                 activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, None, 7 0           activation_364[0][0]             \n",
      "                                                                 activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, None, None, 1 0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_358[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, None, None, 4 1344        conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, None, None, 4 0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, None, None, 3 1548288     activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, None, None, 3 1152        conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, None, None, 3 1152        conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, None, None, 3 0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, None, None, 3 0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, None, None, 3 442368      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, None, None, 3 442368      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, None, None, 3 442368      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, None, None, 3 442368      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, None, None, 3 1152        conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, None, None, 3 1152        conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, None, None, 3 1152        conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, None, None, 3 1152        conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, None, None, 3 960         conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, None, None, 3 0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, None, None, 3 0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, None, None, 3 0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, None, None, 3 0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, None, None, 1 576         conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, None, None, 3 0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_369[0][0]             \n",
      "                                                                 activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, None, 7 0           activation_373[0][0]             \n",
      "                                                                 activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, None, None, 1 0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_367[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, None, None, 5 10245       mixed10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,813,029\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_inception = tf.keras.models.Model(inputs=[inceptionv3.input], outputs=[output])\n",
    "my_inception.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "my_inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, True]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[layer.trainable for layer in my_inception.layers[-5:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*d. Split your dataset into a training set and a test set. Train the model on the training set and evaluate it on the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/FlowersDataset/flower_photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, None, None, 5]), TensorShape([None, None, None, 2048]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(my_inception.layers[-1].output.shape, my_inception.layers[-2].output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2939 images belonging to 5 classes.\n",
      "Found 731 images belonging to 5 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:532 train_step  **\n        loss = self.compiled_loss(\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:205 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1527 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4561 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1117 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, None) and (None, None, None, 5) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-3828f34c63d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m my_inception.fit(datagen.flow_from_directory(folder, target_size=(299,299),subset='training'),\n\u001b[0m\u001b[0;32m      2\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 epochs=20)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    616\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2419\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2420\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2772\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 2774\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2703\u001b[0m     self._function_cache.arg_relaxed_shapes[rank_only_cache_key] = (\n\u001b[0;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[1;32m-> 2705\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   2706\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 2657\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:532 train_step  **\n        loss = self.compiled_loss(\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:205 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1527 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4561 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1117 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, None) and (None, None, None, 5) are incompatible\n"
     ]
    }
   ],
   "source": [
    "my_inception.fit(datagen.flow_from_directory(folder, target_size=(299,299),subset='training'),\n",
    "                validation_data=datagen.flow_from_directory(folder, target_size=(299,299), subset='validation'),\n",
    "                epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.60424435, 0.6158477 , 0.49427906],\n",
       "         [0.61794406, 0.62269753, 0.5011289 ],\n",
       "         [0.61960787, 0.6325563 , 0.5049698 ],\n",
       "         ...,\n",
       "         [0.26513362, 0.21439528, 0.14149924],\n",
       "         [0.31348598, 0.25916132, 0.11776683],\n",
       "         [0.3386542 , 0.2894474 , 0.11087791]],\n",
       "\n",
       "        [[0.60424435, 0.6158477 , 0.49427906],\n",
       "         [0.61794406, 0.62269753, 0.5011289 ],\n",
       "         [0.61960787, 0.6325563 , 0.5049698 ],\n",
       "         ...,\n",
       "         [0.26513362, 0.21439528, 0.14149924],\n",
       "         [0.31348598, 0.25916132, 0.11776683],\n",
       "         [0.3386542 , 0.2894474 , 0.11087791]],\n",
       "\n",
       "        [[0.60424435, 0.6158477 , 0.49427906],\n",
       "         [0.61794406, 0.62269753, 0.5011289 ],\n",
       "         [0.61960787, 0.6325563 , 0.5049698 ],\n",
       "         ...,\n",
       "         [0.26513362, 0.21439528, 0.14149924],\n",
       "         [0.31348598, 0.25916132, 0.11776683],\n",
       "         [0.3386542 , 0.2894474 , 0.11087791]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8352135 , 0.8195272 , 0.5800694 ],\n",
       "         [0.83178854, 0.81610227, 0.5663697 ],\n",
       "         [0.8704891 , 0.83975804, 0.5737328 ],\n",
       "         ...,\n",
       "         [0.48251435, 0.44722024, 0.19296375],\n",
       "         [0.48904145, 0.44705886, 0.1955011 ],\n",
       "         [0.4901961 , 0.44990644, 0.20746881]],\n",
       "\n",
       "        [[0.8352135 , 0.8195272 , 0.5800694 ],\n",
       "         [0.83178854, 0.81610227, 0.5663697 ],\n",
       "         [0.8704891 , 0.83975804, 0.5737328 ],\n",
       "         ...,\n",
       "         [0.48251435, 0.44722024, 0.19296375],\n",
       "         [0.48904145, 0.44705886, 0.1955011 ],\n",
       "         [0.4901961 , 0.44990644, 0.20746881]],\n",
       "\n",
       "        [[0.8352135 , 0.8195272 , 0.5800694 ],\n",
       "         [0.83178854, 0.81610227, 0.5663697 ],\n",
       "         [0.8704891 , 0.83975804, 0.5737328 ],\n",
       "         ...,\n",
       "         [0.48251435, 0.44722024, 0.19296375],\n",
       "         [0.48904145, 0.44705886, 0.1955011 ],\n",
       "         [0.4901961 , 0.44990644, 0.20746881]]],\n",
       "\n",
       "\n",
       "       [[[0.46274513, 0.41960788, 0.4039216 ],\n",
       "         [0.46620014, 0.4230629 , 0.4073766 ],\n",
       "         [0.4666667 , 0.42352945, 0.40784317],\n",
       "         ...,\n",
       "         [0.41867796, 0.3830335 , 0.3644766 ],\n",
       "         [0.4139103 , 0.37647063, 0.3632995 ],\n",
       "         [0.41390976, 0.37647063, 0.36329782]],\n",
       "\n",
       "        [[0.46393704, 0.4207998 , 0.40511352],\n",
       "         [0.466342  , 0.42320475, 0.40751848],\n",
       "         [0.46770018, 0.42456293, 0.40887666],\n",
       "         ...,\n",
       "         [0.4185455 , 0.3832514 , 0.36320776],\n",
       "         [0.4131002 , 0.3778061 , 0.35552728],\n",
       "         [0.41310078, 0.37780666, 0.35552672]],\n",
       "\n",
       "        [[0.4666667 , 0.42352945, 0.40784317],\n",
       "         [0.4666667 , 0.42352945, 0.40784317],\n",
       "         [0.47006387, 0.4269266 , 0.41124034],\n",
       "         ...,\n",
       "         [0.41896775, 0.38367364, 0.36307752],\n",
       "         [0.4156863 , 0.3803922 , 0.35473108],\n",
       "         [0.4156863 , 0.3803922 , 0.35473222]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.20784315, 0.16862746, 0.13333334],\n",
       "         [0.20438813, 0.16517244, 0.12987831],\n",
       "         [0.20390904, 0.16469336, 0.12939924],\n",
       "         ...,\n",
       "         [0.35420063, 0.31500575, 0.27971163],\n",
       "         [0.3612576 , 0.32215092, 0.28685677],\n",
       "         [0.3647059 , 0.3254902 , 0.2901961 ]],\n",
       "\n",
       "        [[0.20784315, 0.16862746, 0.13333334],\n",
       "         [0.20744178, 0.1682261 , 0.13293198],\n",
       "         [0.20738815, 0.16817246, 0.13287835],\n",
       "         ...,\n",
       "         [0.35363242, 0.31500575, 0.27971163],\n",
       "         [0.35829344, 0.32215092, 0.28685677],\n",
       "         [0.3647059 , 0.3254902 , 0.2901961 ]],\n",
       "\n",
       "        [[0.20784315, 0.16862746, 0.13333334],\n",
       "         [0.20784315, 0.16862746, 0.13333334],\n",
       "         [0.20784315, 0.16862746, 0.13333334],\n",
       "         ...,\n",
       "         [0.3535813 , 0.31552285, 0.27919453],\n",
       "         [0.35802728, 0.32484895, 0.2836883 ],\n",
       "         [0.3647059 , 0.3254902 , 0.28702706]]],\n",
       "\n",
       "\n",
       "       [[[0.27011788, 0.23576449, 0.16862746],\n",
       "         [0.27743697, 0.23186977, 0.16862746],\n",
       "         [0.28182888, 0.23477004, 0.17202495],\n",
       "         ...,\n",
       "         [0.23529413, 0.28627452, 0.1137255 ],\n",
       "         [0.23584506, 0.28682545, 0.11427643],\n",
       "         [0.2392157 , 0.2901961 , 0.11764707]],\n",
       "\n",
       "        [[0.27011788, 0.23576449, 0.16862746],\n",
       "         [0.27743697, 0.23186977, 0.16862746],\n",
       "         [0.28182888, 0.23477004, 0.17202495],\n",
       "         ...,\n",
       "         [0.23529413, 0.28627452, 0.1137255 ],\n",
       "         [0.23584506, 0.28682545, 0.11427643],\n",
       "         [0.2392157 , 0.2901961 , 0.11764707]],\n",
       "\n",
       "        [[0.27011788, 0.23576449, 0.16862746],\n",
       "         [0.27743697, 0.23186977, 0.16862746],\n",
       "         [0.28182888, 0.23477004, 0.17202495],\n",
       "         ...,\n",
       "         [0.23529413, 0.28627452, 0.1137255 ],\n",
       "         [0.23584506, 0.28682545, 0.11427643],\n",
       "         [0.2392157 , 0.2901961 , 0.11764707]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44909897, 0.4534909 , 0.18917602],\n",
       "         [0.47152653, 0.45832634, 0.1745379 ],\n",
       "         [0.48130482, 0.45542607, 0.17934403],\n",
       "         ...,\n",
       "         [0.76516074, 0.51418036, 0.02675025],\n",
       "         [0.74564904, 0.49411768, 0.00330558],\n",
       "         [0.7458752 , 0.49044916, 0.02510163]],\n",
       "\n",
       "        [[0.44909897, 0.4534909 , 0.18917602],\n",
       "         [0.47152653, 0.45832634, 0.1745379 ],\n",
       "         [0.48130482, 0.45542607, 0.17934403],\n",
       "         ...,\n",
       "         [0.76516074, 0.51418036, 0.02675025],\n",
       "         [0.74564904, 0.49411768, 0.00330558],\n",
       "         [0.7458752 , 0.49044916, 0.02510163]],\n",
       "\n",
       "        [[0.44909897, 0.4534909 , 0.18917602],\n",
       "         [0.47152653, 0.45832634, 0.1745379 ],\n",
       "         [0.48130482, 0.45542607, 0.17934403],\n",
       "         ...,\n",
       "         [0.76516074, 0.51418036, 0.02675025],\n",
       "         [0.74564904, 0.49411768, 0.00330558],\n",
       "         [0.7458752 , 0.49044916, 0.02510163]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.9946233 , 0.9946233 , 0.9946233 ],\n",
       "         [0.99462914, 0.99462914, 0.99462914],\n",
       "         [0.9946386 , 0.9946386 , 0.9946386 ],\n",
       "         ...,\n",
       "         [0.99966526, 0.99966526, 0.99966526],\n",
       "         [0.996185  , 0.996185  , 0.996185  ],\n",
       "         [0.99999017, 0.99999017, 0.99999017]],\n",
       "\n",
       "        [[0.9960785 , 0.9960785 , 0.9960785 ],\n",
       "         [0.9960785 , 0.9960785 , 0.9960785 ],\n",
       "         [0.9960785 , 0.9960785 , 0.9960785 ],\n",
       "         ...,\n",
       "         [0.9957993 , 0.9957993 , 0.9957993 ],\n",
       "         [0.9924623 , 0.9924623 , 0.9924623 ],\n",
       "         [0.99998057, 0.99998057, 0.99998057]],\n",
       "\n",
       "        [[0.9960785 , 0.9960785 , 0.9960785 ],\n",
       "         [0.9960785 , 0.9960785 , 0.9960785 ],\n",
       "         [0.9960785 , 0.9960785 , 0.9960785 ],\n",
       "         ...,\n",
       "         [0.9957781 , 0.9957781 , 0.9957781 ],\n",
       "         [0.99244756, 0.99244756, 0.99244756],\n",
       "         [0.99998057, 0.99998057, 0.99998057]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.23612076, 0.3307585 , 0.19401687],\n",
       "         [0.25002003, 0.35623038, 0.18009448],\n",
       "         [0.2281762 , 0.33796105, 0.18105039],\n",
       "         ...,\n",
       "         [0.24657197, 0.32212245, 0.1560159 ],\n",
       "         [0.25303516, 0.32881016, 0.1654513 ],\n",
       "         [0.24766259, 0.32882193, 0.1573699 ]],\n",
       "\n",
       "        [[0.22460493, 0.30897963, 0.17487794],\n",
       "         [0.2510855 , 0.3606696 , 0.1738581 ],\n",
       "         [0.2430566 , 0.35285076, 0.19583903],\n",
       "         ...,\n",
       "         [0.24466747, 0.32861888, 0.15640903],\n",
       "         [0.25217524, 0.33636376, 0.17852393],\n",
       "         [0.24155453, 0.3317351 , 0.167047  ]],\n",
       "\n",
       "        [[0.1853312 , 0.2624802 , 0.13223146],\n",
       "         [0.26533794, 0.36774167, 0.1843037 ],\n",
       "         [0.23915334, 0.34894753, 0.18816286],\n",
       "         ...,\n",
       "         [0.25151718, 0.34419963, 0.16460377],\n",
       "         [0.25759038, 0.35284373, 0.2014745 ],\n",
       "         [0.24701643, 0.3341244 , 0.18340875]]],\n",
       "\n",
       "\n",
       "       [[[0.41176474, 0.62888515, 0.8916303 ],\n",
       "         [0.41176474, 0.62889403, 0.8916391 ],\n",
       "         [0.41176474, 0.62890285, 0.891648  ],\n",
       "         ...,\n",
       "         [0.5414229 , 0.73308694, 0.9037984 ],\n",
       "         [0.5414141 , 0.7330958 , 0.9038029 ],\n",
       "         [0.5414052 , 0.73310465, 0.9038073 ]],\n",
       "\n",
       "        [[0.40612933, 0.6189979 , 0.89019614],\n",
       "         [0.40613818, 0.61901116, 0.89019614],\n",
       "         [0.40614703, 0.61902446, 0.89019614],\n",
       "         ...,\n",
       "         [0.55018973, 0.7294118 , 0.90705246],\n",
       "         [0.5501764 , 0.7294118 , 0.90703917],\n",
       "         [0.5501631 , 0.7294118 , 0.9070259 ]],\n",
       "\n",
       "        [[0.41850704, 0.63270265, 0.8950579 ],\n",
       "         [0.4184805 , 0.63267165, 0.8950491 ],\n",
       "         [0.41845387, 0.63264066, 0.8950402 ],\n",
       "         ...,\n",
       "         [0.5581732 , 0.72810143, 0.91372555],\n",
       "         [0.55816877, 0.72810584, 0.91372555],\n",
       "         [0.5581643 , 0.72811025, 0.91372555]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.45060742, 0.454529  , 0.2908967 ],\n",
       "         [0.45057195, 0.45449352, 0.29087016],\n",
       "         [0.45053655, 0.45445812, 0.29084358],\n",
       "         ...,\n",
       "         [0.08113909, 0.14161994, 0.05053693],\n",
       "         [0.08115681, 0.14164208, 0.05051479],\n",
       "         [0.08117452, 0.14166424, 0.05049264]],\n",
       "\n",
       "        [[0.42792043, 0.431842  , 0.2611402 ],\n",
       "         [0.42796028, 0.43188184, 0.26118892],\n",
       "         [0.42800015, 0.43192172, 0.26123762],\n",
       "         ...,\n",
       "         [0.07826472, 0.1352108 , 0.0644559 ],\n",
       "         [0.07825585, 0.13520637, 0.06444261],\n",
       "         [0.078247  , 0.13520195, 0.06442932]],\n",
       "\n",
       "        [[0.3621624 , 0.3713063 , 0.1961461 ],\n",
       "         [0.36225986, 0.37139487, 0.19623913],\n",
       "         [0.3623573 , 0.37148345, 0.19633213],\n",
       "         ...,\n",
       "         [0.08086229, 0.13576424, 0.0720789 ],\n",
       "         [0.08086672, 0.13576867, 0.07207447],\n",
       "         [0.08087114, 0.1357731 , 0.07207004]]],\n",
       "\n",
       "\n",
       "       [[[0.07169347, 0.08265588, 0.05349379],\n",
       "         [0.12015322, 0.11446565, 0.09333852],\n",
       "         [0.1902607 , 0.16704012, 0.13368526],\n",
       "         ...,\n",
       "         [0.27179193, 0.22559837, 0.17875585],\n",
       "         [0.28453302, 0.22178791, 0.17080753],\n",
       "         [0.28887454, 0.22612944, 0.17514905]],\n",
       "\n",
       "        [[0.07169347, 0.08265588, 0.05349379],\n",
       "         [0.12015322, 0.11446565, 0.09333852],\n",
       "         [0.1902607 , 0.16704012, 0.13368526],\n",
       "         ...,\n",
       "         [0.27179193, 0.22559837, 0.17875585],\n",
       "         [0.28453302, 0.22178791, 0.17080753],\n",
       "         [0.28887454, 0.22612944, 0.17514905]],\n",
       "\n",
       "        [[0.07169347, 0.08265588, 0.05349379],\n",
       "         [0.12015322, 0.11446565, 0.09333852],\n",
       "         [0.1902607 , 0.16704012, 0.13368526],\n",
       "         ...,\n",
       "         [0.27179193, 0.22559837, 0.17875585],\n",
       "         [0.28453302, 0.22178791, 0.17080753],\n",
       "         [0.28887454, 0.22612944, 0.17514905]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.130517  , 0.13443857, 0.11090916],\n",
       "         [0.11891963, 0.1228412 , 0.09450722],\n",
       "         [0.21290663, 0.21453701, 0.14650573],\n",
       "         ...,\n",
       "         [0.11820178, 0.13410437, 0.0992429 ],\n",
       "         [0.13987352, 0.14989671, 0.10327642],\n",
       "         [0.13007255, 0.13791569, 0.08693529]],\n",
       "\n",
       "        [[0.130517  , 0.13443857, 0.11090916],\n",
       "         [0.11891963, 0.1228412 , 0.09450722],\n",
       "         [0.21290663, 0.21453701, 0.14650573],\n",
       "         ...,\n",
       "         [0.11820178, 0.13410437, 0.0992429 ],\n",
       "         [0.13987352, 0.14989671, 0.10327642],\n",
       "         [0.13007255, 0.13791569, 0.08693529]],\n",
       "\n",
       "        [[0.130517  , 0.13443857, 0.11090916],\n",
       "         [0.11891963, 0.1228412 , 0.09450722],\n",
       "         [0.21290663, 0.21453701, 0.14650573],\n",
       "         ...,\n",
       "         [0.11820178, 0.13410437, 0.0992429 ],\n",
       "         [0.13987352, 0.14989671, 0.10327642],\n",
       "         [0.13007255, 0.13791569, 0.08693529]]]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen.flow_from_directory(folder).__next__()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
