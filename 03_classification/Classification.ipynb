{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download the mnist dataset\n",
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n",
    "# We need to flatten our images for sklearn\n",
    "x_train = x_train.reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13cf18d9518>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADZdJREFUeJzt3X+IXPW5x/HPY378k9RoyGiDidnc\nEuSGoKaMUfBavJSt6TUSRSrJH3XF0q0QfxTyh+I/EUFY5NpW8BLc3CyJ0qQptrkuqL0JQdBiFUcN\njU1qq7JtY0IywUCtoM3G5/6xJ5c17nxnMnPOnNk87xeEmTnP+fEw5LNnZr5z5mvuLgDxXFB2AwDK\nQfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwQ1s5sHW7Bggff19XXzkEAoY2NjOnHihLWybkfh\nN7PVkp6UNEPSf7v7UGr9vr4+1Wq1Tg4JIKFarba8btsv+81shqT/kvRdScslrTez5e3uD0B3dfKe\nf5Wk9939Q3f/p6RfSFqbT1sAitZJ+C+T9LdJjw9ny77EzAbNrGZmtXq93sHhAOSpk/BP9aHCV64P\ndvdhd6+6e7VSqXRwOAB56iT8hyUtnvR4kaQjnbUDoFs6Cf+bkpaZ2VIzmy1pnaTRfNoCULS2h/rc\nfdzM7pX0v5oY6htx9z/k1hmAQnU0zu/uL0p6MadeAHQRX+8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4\ngaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqI5m6TWzMUmfSDotadzdq3k0BaB4HYU/8+/ufiKH/QDo\nIl72A0F1Gn6XtMfM3jKzwTwaAtAdnb7sv97dj5jZJZL2mtkf3f2VyStkfxQGJenyyy/v8HAA8tLR\nmd/dj2S3xyXtlrRqinWG3b3q7tVKpdLJ4QDkqO3wm9kcM/vamfuSviPp3bwaA1CsTl72Xyppt5md\n2c8Od/9NLl0BKFzb4Xf3DyVdlWMvCGZ8fDxZv//++5P1zZs3J+s33XRTw9pzzz2X3Hbu3LnJ+vmA\noT4gKMIPBEX4gaAIPxAU4QeCIvxAUHlc1YfAPv3002T9sccea1gbHR1Nbnvw4MFkPfuOSUN79uxp\nWNuxY0dy28HB8/9SFc78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/xIuvPOO5P1F154IVk/efJk\nnu3k5qqruBqdMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4/3nugw8+SNYHBgaS9ddeey3Pdrpq\n3rx5DWvLli3rYie9iTM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTVdJzfzEYkrZF03N1XZMvmS9ol\nqU/SmKQ73L03L9wOYOfOnQ1rd911V3LbU6dO5dzNl/X39zes7d27t6N933LLLcn6008/3bA2f/78\njo59PmjlzL9N0uqzlj0kaZ+7L5O0L3sMYBppGn53f0XSx2ctXitpe3Z/u6Rbc+4LQMHafc9/qbsf\nlaTs9pL8WgLQDYV/4Gdmg2ZWM7NavV4v+nAAWtRu+I+Z2UJJym6PN1rR3Yfdveru1Uql0ubhAOSt\n3fCPSjpzOdiApOfzaQdAtzQNv5ntlPQ7SVeY2WEz+4GkIUn9ZvZnSf3ZYwDTSNNxfndf36D07Zx7\nQQObNm1K1h9//PGGtU7H8detW5esX3TRRcn666+/3vaxN27cmKwPDaXPOTNmzGj72BHwDT8gKMIP\nBEX4gaAIPxAU4QeCIvxAUPx0dw9IXZIrpYfyJOnzzz9vWLvwwguT2953333J+pVXXpmsP/jgg8n6\n2NhYsp5y7bXXJusM5XWGMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4fxeMj48n6yMjI8l6ahy/\nmWZj4Z999lmy3uySXnc/557QGzjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPN3wcmT6dnL9+3b\nV9qxn3jiicKO3czs2bOT9SVLlnSpk5g48wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUE3H+c1sRNIa\nScfdfUW27BFJP5RUz1Z72N1fLKrJ6W50dLTsFtp2xRVXJOvvvfde2/vu7+9P1q+55pq2943mWjnz\nb5O0eorlP3X3q7N/BB+YZpqG391fkfRxF3oB0EWdvOe/18x+b2YjZnZxbh0B6Ip2w79Z0jckXS3p\nqKSGXxA3s0Ezq5lZrV6vN1oNQJe1FX53P+bup939C0lbJK1KrDvs7lV3r1YqlXb7BJCztsJvZgsn\nPbxN0rv5tAOgW1oZ6tsp6UZJC8zssKRNkm40s6sluaQxST8qsEcABWgafndfP8XirQX0ct4aGBhI\n1nft2pWsv/zyy8n66dOnG9ZmzZqV3HbNmjXJerNx/qGhoWQ9Zfny5W1vi87xDT8gKMIPBEX4gaAI\nPxAU4QeCIvxAUPx0dxfMnJl+mvfs2ZOsv/POO8n6gQMHGtaaTbHd7OezV6xYkax34u677y5s32iO\nMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4/zSwcuXKjuopjz76aLJ+8ODBtvctSdddd13D2tKl\nSzvaNzrDmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKc/zz30UcfJetPPfVUoce/5557Gtaa/ZYA\nisWZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCajrOb2aLJT0j6euSvpA07O5Pmtl8Sbsk9Ukak3SH\nu58srlW046WXXkrWT5w40dH+582bl6zffvvtHe0fxWnlzD8uaaO7/6uk6yRtMLPlkh6StM/dl0na\nlz0GME00Db+7H3X3t7P7n0g6JOkySWslbc9W2y7p1qKaBJC/c3rPb2Z9klZKekPSpe5+VJr4AyHp\nkrybA1CclsNvZnMl/UrSj9397+ew3aCZ1cysVq/X2+kRQAFaCr+ZzdJE8H/u7r/OFh8zs4VZfaGk\n41Nt6+7D7l5192qlUsmjZwA5aBp+MzNJWyUdcvefTCqNShrI7g9Iej7/9gAUpZVLeq+X9H1JB8xs\nf7bsYUlDkn5pZj+Q9FdJ3yumRTTz6quvNqxt2LCh0GNv27YtWZ8zZ06hx0f7mobf3X8ryRqUv51v\nOwC6hW/4AUERfiAowg8ERfiBoAg/EBThB4Lip7ungVOnTiXr+/fvb1hrtm0zN9xwQ7J+8803d7R/\nlIczPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTj/NJC6Xl+SHnjggcKO/eyzzybrM2fyX2i64swP\nBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ExSDsN7N69u7B9r169OllftGhRYcdGuTjzA0ERfiAowg8E\nRfiBoAg/EBThB4Ii/EBQTcf5zWyxpGckfV3SF5KG3f1JM3tE0g8l1bNVH3b3F4tq9Hy2devWZH3L\nli1t73vJkiXJ+q5du5L1Cy7g/HC+auVLPuOSNrr722b2NUlvmdnerPZTd//P4toDUJSm4Xf3o5KO\nZvc/MbNDki4rujEAxTqn13Rm1idppaQ3skX3mtnvzWzEzC5usM2gmdXMrFav16daBUAJWg6/mc2V\n9CtJP3b3v0vaLOkbkq7WxCuDJ6bazt2H3b3q7tVKpZJDywDy0FL4zWyWJoL/c3f/tSS5+zF3P+3u\nX0jaImlVcW0CyFvT8JuZSdoq6ZC7/2TS8oWTVrtN0rv5twegKObu6RXM/k3Sq5IOaGKoT5IelrRe\nEy/5XdKYpB9lHw42VK1WvVarddgygEaq1apqtZq1sm4rn/b/VtJUO2NMH5jG+AYHEBThB4Ii/EBQ\nhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqKbX8+d6MLO6pL9MWrRA0omu\nNXBuerW3Xu1Lord25dnbEndv6ffyuhr+rxzcrObu1dIaSOjV3nq1L4ne2lVWb7zsB4Ii/EBQZYd/\nuOTjp/Rqb73al0Rv7Sqlt1Lf8wMoT9lnfgAlKSX8ZrbazN4zs/fN7KEyemjEzMbM7ICZ7TezUn9n\nPJsG7biZvTtp2Xwz22tmf85up5wmraTeHjGzj7Lnbr+Z/UdJvS02s5fN7JCZ/cHMHsiWl/rcJfoq\n5Xnr+st+M5sh6U+S+iUdlvSmpPXufrCrjTRgZmOSqu5e+piwmX1L0j8kPePuK7Jlj0v62N2Hsj+c\nF7v7gz3S2yOS/lH2zM3ZhDILJ88sLelWSXepxOcu0dcdKuF5K+PMv0rS++7+obv/U9IvJK0toY+e\n5+6vSPr4rMVrJW3P7m/XxH+ermvQW09w96Pu/nZ2/xNJZ2aWLvW5S/RVijLCf5mkv016fFi9NeW3\nS9pjZm+Z2WDZzUzh0jMzI2W3l5Tcz9maztzcTWfNLN0zz107M17nrYzwTzX7Ty8NOVzv7t+U9F1J\nG7KXt2hNSzM3d8sUM0v3hHZnvM5bGeE/LGnxpMeLJB0poY8pufuR7Pa4pN3qvdmHj52ZJDW7PV5y\nP/+vl2ZunmpmafXAc9dLM16XEf43JS0zs6VmNlvSOkmjJfTxFWY2J/sgRmY2R9J31HuzD49KGsju\nD0h6vsRevqRXZm5uNLO0Sn7uem3G61K+5JMNZfxM0gxJI+7+WNebmIKZ/YsmzvbSxCSmO8rszcx2\nSrpRE1d9HZO0SdL/SPqlpMsl/VXS99y96x+8NejtRp3jzM0F9dZoZuk3VOJzl+eM17n0wzf8gJj4\nhh8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaD+Dyds1wog2iMxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13cf185ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's load an image and look at it\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = x_train[36000]\n",
    "plt.imshow(some_digit, cmap=plt.cm.binary, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work on a binary classifier to determine if an image has a 5 or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5) # True for all 5's, False for any other digits\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Okay, now let's pick a classifier and train it... Scikit-Learn's `SGDClassifier` (Stochastic Gradient Descent) class has the advantage of being capable of handling very large datasets efficiently. This is in part because SGD deals with training instances independently, one at a time (which also makes SGD well suited for *online learning*)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "sgd_clf.fit(x_train, y_train_5) # 'The SGDClassifier relies on randomness during training (hence the name \"stochastic\").'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Accuracy Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, x_train, y_train_5, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting >95% accuracy on all folds of the training set, which seems great! However, the data is extremely skewed, with only 10% of the data being 5's and 90% not being such.\n",
    "\n",
    "Even if the model was to guess 100% of the time that the label is not a 5, it would still get 90% accuracy, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91125, 0.90855, 0.90915])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, x_train, y_train_5, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using accuracy, \"a much better way to evaluate the performance of a classifier is to look at the *confusion matrix.* The general idea is to count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5's with 3's, you would look in the 5th row and the 3rd column.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, x_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[ true negatives | false positives ]    ideal:`\n",
    "\n",
    "`[ guessed not 5, | guessed 5,      ]    [m,0]`\n",
    "\n",
    "`[ was not 5      | was not 5       ]    [0,n]`\n",
    "\n",
    "`[----------------------------------]`\n",
    "\n",
    "`[ false negatives| true positives  ] `\n",
    "\n",
    "`[ guessed not 5, | guessed 5,      ]`\n",
    "\n",
    "`[ was 5          | was 5           ]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to look at the accuracy is through the percentage of correct positive predictions, known as the **precision** of the classifier:\n",
    "\n",
    "precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Precision is typically used along with another metric named **recall**\" (or **sensitivity** or **true positive rate**).\n",
    "\n",
    "recall = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Scikit-Learn provides several function to compute classifier metrics, including precision and recall.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.8370879772350012\n",
      "Recall score: 0.6511713705958311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print('Precision score:', precision_score(y_train_5, y_train_pred)) # Percentage of claims that it is a 5 that are correct\n",
    "print('Recall score:', recall_score(y_train_5, y_train_pred)) # Percentage of 5's that it was able to detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
